{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/dfs/scratch0/paroma/snorkel')\n",
    "from snorkel.learning import LogisticRegression\n",
    "disc_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.load('/dfs/scratch0/paroma/reef/bone_tumor_reef_pruner.npy')\n",
    "\n",
    "labels = np.load('/dfs/scratch0/paroma/data/bone_tumor/ground.npy')\n",
    "features = np.load('/dfs/scratch0/paroma/data/bone_tumor/features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_all = []\n",
    "pr_all = []\n",
    "re_all = []\n",
    "val_acc_all = []\n",
    "\n",
    "\n",
    "lr_arr = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1]\n",
    "reg_arr = [1e-1,1e-2,1e-3]\n",
    "n_epochs_arr = [50,100,150,200]\n",
    "\n",
    "for lr in lr_arr:\n",
    "    for reg in reg_arr:\n",
    "        for n_epochs in n_epochs_arr:\n",
    "            disc_model.train(features[0:400,:], (train_labels+1.)/2., reg=reg, lr=lr, batch_size=400, n_epochs=n_epochs, rebalance=False, print_freq=0)\n",
    "            predictions = disc_model.predictions(features[400:600,:])\n",
    "            \n",
    "            val_acc_all.append(np.sum(predictions == labels[400:600])/float(np.shape(labels[400:600])[0]))\n",
    "            f1_all.append(metrics.f1_score(labels[400:600], predictions))\n",
    "            pr_all.append(metrics.precision_score(labels[400:600], predictions))\n",
    "            re_all.append(metrics.recall_score(labels[400:600], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lr:  0.005\n",
      "Best Reg:  0.001\n",
      "Best Dropout:  50\n",
      "F1 Score:  0.6880733944954127\n"
     ]
    }
   ],
   "source": [
    "ii,jj,kk = np.unravel_index(np.argmax(f1_all), (5,3,4))\n",
    "print 'Best Lr: ', lr_arr[ii]\n",
    "print 'Best Reg: ', reg_arr[jj]\n",
    "print 'Best Dropout: ', n_epochs_arr[kk]\n",
    "print 'F1 Score: ', max(f1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Val Acc:  0.66\n",
      "\n",
      "Best F1:  0.6880733944954127\n",
      "Best Pr:  0.5905511811023622\n",
      "Best Re:  0.8241758241758241\n"
     ]
    }
   ],
   "source": [
    "print 'Best Val Acc: ', np.max(val_acc_all)\n",
    "print '\\nBest F1: ', np.max(f1_all)\n",
    "print 'Best Pr: ', pr_all[np.argmax(f1_all)]\n",
    "print 'Best Re: ', re_all[np.argmax(f1_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
